\chapter{Literature Review}

\todo{This is all very general: perhaps make more specific as more
  details of the project get worked out}

This chapter reviews the background of the project: the traditional
methods of garbage collection, more complicated collectors, methods of
algorithm and software verification, and current work in the
production of verified garbage collectors.

\section{Garbage Collection}

Garbage collection is the process of automatically reclaiming unneeded
memory from a program. In languages with manual memory management,
such as C, a programmer can allocate new memory with \texttt{malloc},
but then must remember to release it with \texttt{free}. If this is
not done, a memory leak occurs, and the program may gradually consume
more and more memory.

In a garbage collected language, however, the programmer can allocate
new memory, but typically cannot (and does not need to) explicitly
deallocate it. Instead, some runtime system determines when blocks of
memory are no longer needed, typically by determining if they can be
reached by following pointers from the ``roots''---the set of
variables in scope---or not.

\subsection{The Traditional Algorithms}

We can divide most garbage collection algorithms into four camps:
reference counting, mark-sweep, copying, and mark-compact. Each is
suited to different use-cases, and the choice of which to use is often
determined by the behaviour of the particular system in which they
will be used.

\subsubsection{Reference Counting}

Reference counting is a very simple scheme where each block contains a
\textit{reference count}, some integer field which keeps track of the
number of references to the block. In the most basic form of the
algorithm, the compiler maintains a write barrier, which increments
and decrements the count immediately as references are created or
destroyed. Furthermore, as soon as the count reaches zero, the block
is deallocated\cite{Collins60}.

This strategy seems good, as it distributes the load of memory
management throughout the computation, however it results in the
problem of unbounded time taken to free a block, as freeing it may
cause other things to be freed, and so on\cite{GarbageCollection}.
This problem can be offset by pushing to a free list, rather than
doing the recursive free, or by deferring the reference counting.

The Deutsch--Bobrow algorithm is an example of this kind, where
reference count adjustments are stored in a transaction file, which is
routinely processed to adjust the state of the entire
system\cite{Deutsch76}.

A fatal flaw, alas, with reference counting is that it cannot reclaim
self-referential structures, even if they are
garbage\cite{McBeth63}. Some systems make use of ``weak references'',
references which do not cause the count to be modified, to offset
this. However, this places a burden on the programmer and so loses
some of the convenience of the system.

\subsubsection{Mark-Sweep}

The mark-sweep method was invented for the early Lisp
systems\cite{McCarthy60}, and it functions by giving every block a
\textit{mark bit}, which is initially unset. Upon running out of
memory, all cells reachable from the roots are marked (this can be
done recursively quite simply), and then all blocks in the heap are
examined: those which are unmarked are freed, and those which are
marked are unmarked, ready for the next collection.

Compared to reference counting, mark-sweep is a very different beast:
it handles cycles easily and there is no overhead on pointer
operations. It does, however, ``stop the world'' in order to perform a
collection\cite{GarbageCollection}. Furthermore, garbage collection
becomes more frequent as heap residency increases.

These problems can be offset somewhat by interleaving the sweeping
with the mutator (the user program, so called because it mutates the
heap). Hughes's lazy sweep algorithm\cite{Hughes82} does this by
performing a fixed amount of sweeping at each allocation, and so the
only long garbage collection pause happens when the heap needs to be
marked.

\subsubsection{Copying}

Copying collectors divide the heap into two \textit{semispaces}, where
allocation is only done in one of them at a time. In garbage
collection, all live block are copied to the other semispace, and the
roles of the semispaces are swapped\cite{Fenichel69}. Unlike
mark-sweep collectors, the pause time of a copying collector is
proportional only to the number of live blocks in the heap, rather
than the size of the entire heap.

Copying collectors have become fairly popular due to the low cost of
allocation and reduction of fragmentation, however it has a cost of a
half of the heap space\cite{GarbageCollection}.

\subsubsection{Mark-Compact}

Heap fragmentation can be a great problem: there may be more than
enough space to allocate something, but not enough contiguous space to
do so. Furthermore, high fragmentation can increase the rate of page
faults and cache misses, reducing the performance of the mutator.

Thus, we come to the mark-compact collectors. These first mark the
live portion of the heap, and then copy marked blocks over garbage
ones, moving everything towards one end of the heap in order to remove
fragmentation. There are three ways of performing this compacting:
blocks can be moved without regard for their original order; blocks
which point to each other can be placed next to each other; and blocks
can simply ``slide'' towards one end of the heap.

Unfortunately, these collectors require multiple traversals over the
heap, and so are potentially even slower than mark-sweep
collectors\cite{GarbageCollection}.

\subsection{Hybrid Collectors}

Sometimes any one of the traditional algorithms is not quite good
enough for a particular problem, and a better collector can be formed
by combining them. For example, reference counting could be combined
with periodic copying, in order to reclaim cyclic structures and
reduce fragmentation. For another example, Immix\cite{Blackburn08} is
a hybrid mark-region (memory is divided into large regions, inside
which allocation occurs) and copying collector.

\subsubsection{Generational Collectors}

Generational garbage collection is a type of hybrid collector: the
heap is divided into a number of \textit{generations}, where each
generation holds progressively older blocks. This is based on
empirical observations of block lifetimes resulting in the
generational hypothesis: young objects die quickly, whereas old
objects stick around\cite{Ungar84}.

Allocation happens in the youngest generation, and when that fills up
a \textit{minor collection} is started. The generation is garbage
collected, and old enough blocks get copied to the next generation. In
the simplest case, all live blocks at the time of a minor collection
get promoted. If the entire heap is full, a \textit{major collection}
is started, which uses some other garbage collection
algorithm\cite{GarbageCollection}.

Generational garbage collection tends to perform well for languages
where old-to-young pointers are rare, such as most functional
languages, and so has become fairly popular amongst implementers of
such languages.

\section{Algorithm Verification}

\todo{What is verification}

\subsection{Verification by Proof}

\todo{How to take some code and a specification and prove the two equivalent}

\subsection{Verification by Extraction}

\todo{How to refine a specification until we can pluck out code}

\subsection{Proof Assistants}

\todo{If I decide to use one, brief summary of what they are, and then
  a slightly more detailed subsubsection about the one I will use}

\section{Verified Garbage Collection}

\todo{Myreen \& Birkedal papers. Comparison of approach
  (extraction/proof). Comparison of logic (HOL/separation). Comparison
  of goals (new, old). Comparison of collectors (both
  copying). Contributions (beyond the obvious one).}
